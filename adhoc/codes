import numpy as np
import pandas as pd

def rank_numeric_features_by_worst_tail_bad_rate(
    data: pd.DataFrame,
    bad_flag: str,
    num_list: list,
    data_dictionary: pd.DataFrame = None,
    worst_pct: float = 0.05,          # e.g. 0.05 for worst 5%
    min_non_missing: int = 200,
    missing_sentinels: tuple = (-9999,),
    direction_default: int = 0,       # 0 => infer if missing
) -> pd.DataFrame:
    """
    Rank numerical features by bad rate in the worst X% tail, using predefined direction from data_dictionary when available.

    data_dictionary expected columns (case-insensitive):
      - Variable
      - Definition
      - Direction  (commonly 1 = high_worse, -1 = low_worse, 0/NaN = unknown)

    Mismatch logic (as requested):
      cleaned_variable_name = col.split('_')[-1] if '_' in col else col
      cleaned_variable_name = col.rstrip(' -') if ' -' in col else col

    Returns a ranked table with:
      feature (raw col name), cleaned_name, definition, direction_used, cutoff, tail_n, tail_bad_n, tail_bad_rate
    """

    if not (0 < worst_pct < 1):
        raise ValueError("worst_pct must be between 0 and 1 (e.g., 0.05 for 5%).")

    df = data.copy()

    # --- target cleaning ---
    y = pd.to_numeric(df[bad_flag], errors="coerce")
    df = df.loc[y.isin([0, 1])].copy()
    df[bad_flag] = y.loc[df.index].astype(int)

    overall_bad_rate = df[bad_flag].mean()
    if pd.isna(overall_bad_rate):
        raise ValueError("Overall bad rate is NaN (bad_flag might be empty after cleaning).")

    # --- normalize data_dictionary columns (case-insensitive) ---
    dd = None
    if data_dictionary is not None:
        dd = data_dictionary.copy()
        dd.columns = [c.strip().lower() for c in dd.columns]

        # accept both "variable"/"definition"/"direction" in any case
        required = {"variable", "definition", "direction"}
        if not required.issubset(set(dd.columns)):
            raise ValueError(f"data_dictionary must include columns: {required} (case-insensitive). Got: {set(dd.columns)}")

        dd["variable"] = dd["variable"].astype(str).str.strip()

        # quick lookup table by variable
        dd_lookup = dd.set_index("variable", drop=False)

    # --- cleaning function (exact logic you provided) ---
    def clean_variable_name(target_variable: str) -> str:
        s = str(target_variable)
        cleaned = s.split("_")[-1] if "_" in s else s
        cleaned = cleaned.rstrip(" -") if " -" in cleaned else cleaned
        return cleaned

    results = []

    for col in num_list:
        if col not in df.columns:
            continue

        s_raw = pd.to_numeric(df[col], errors="coerce")

        # treat sentinels as missing
        for ms in missing_sentinels:
            s_raw = s_raw.mask(s_raw == ms)

        mask = s_raw.notna()
        n_non_missing = int(mask.sum())
        if n_non_missing < min_non_missing:
            continue

        x = s_raw.loc[mask]
        y_sub = df.loc[mask, bad_flag]

        cleaned_name = clean_variable_name(col)

        # --- get direction & definition from dictionary if possible ---
        definition = None
        direction = direction_default

        if dd is not None and cleaned_name in dd_lookup.index:
            row = dd_lookup.loc[cleaned_name]
            definition = row.get("definition", None)
            d = row.get("direction", np.nan)
            if pd.notnull(d):
                try:
                    direction = int(float(d))
                except Exception:
                    direction = direction_default

        # direction meaning:
        #  1 => high values are worse (worst tail = top X%)
        # -1 => low values are worse (worst tail = bottom X%)
        #  0/unknown => infer via Spearman correlation with target
        inferred_corr = np.nan
        direction_used = direction

        if direction_used == 0:
            inferred_corr = x.corr(y_sub, method="spearman")
            if pd.isna(inferred_corr) or inferred_corr == 0:
                direction_used = 1  # fallback
            else:
                direction_used = 1 if inferred_corr > 0 else -1

        # --- compute worst-tail cutoff + bad rate ---
        if direction_used == 1:
            cutoff = float(x.quantile(1 - worst_pct))
            tail_mask = x >= cutoff
            tail_side = f"top_{int(worst_pct*100)}%"
        else:
            cutoff = float(x.quantile(worst_pct))
            tail_mask = x <= cutoff
            tail_side = f"bottom_{int(worst_pct*100)}%"

        tail_n = int(tail_mask.sum())
        if tail_n == 0:
            continue

        tail_bad_n = int(y_sub.loc[tail_mask].sum())
        tail_bad_rate = tail_bad_n / tail_n

        results.append({
            "feature": col,                         # raw dataset column name
            "cleaned_name": cleaned_name,          # cleaned name used for dictionary matching
            "definition": definition,              # from data_dictionary['definition']
            "direction_used": direction_used,      # +1 high_worse / -1 low_worse
            "tail_side": tail_side,
            "cutoff": cutoff,
            "tail_n": tail_n,                      # volume
            "tail_bad_n": tail_bad_n,              # bad volume
            "tail_bad_rate": tail_bad_rate,        # bad rate in worst tail
            "overall_bad_rate": overall_bad_rate,
            "spearman_corr_if_inferred": inferred_corr
        })

    out = pd.DataFrame(results)
    if out.empty:
        return out

    out = out.sort_values(["tail_bad_rate", "tail_n"], ascending=[False, False]).reset_index(drop=True)
    out.insert(0, "rank", np.arange(1, len(out) + 1))
    return out



import plotly.express as px

def plot_top_worst_tail_bad_rates_plotly(
    rank_table,
    top_n=20,
    use_cleaned_name=False,
    show_pct=True
):
    if rank_table is None or rank_table.empty:
        raise ValueError("rank_table is empty.")

    label_col = "cleaned_name" if use_cleaned_name else "feature"

    dfp = rank_table.head(top_n).copy()
    dfp = dfp.sort_values("tail_bad_rate", ascending=True)

    # Format display values
    if show_pct:
        dfp["bad_rate_display"] = (dfp["tail_bad_rate"] * 100).round(2).astype(str) + "%"
        x_vals = dfp["tail_bad_rate"] * 100
        x_label = "Bad rate in worst tail (%)"
    else:
        dfp["bad_rate_display"] = dfp["tail_bad_rate"].round(4).astype(str)
        x_vals = dfp["tail_bad_rate"]
        x_label = "Bad rate in worst tail"

    fig = px.bar(
        dfp,
        x=x_vals,
        y=dfp[label_col].astype(str),
        orientation="h",
        text="bad_rate_display",
        hover_data={
            "tail_n": True,              # volume
            "tail_bad_n": True,          # bad volume
            "cutoff": True,
            "definition": True,
            "direction_used": True,
            "tail_side": True,
        },
        labels={
            "x": x_label,
            "y": "Feature"
        },
        title=f"Top {min(top_n, len(rank_table))} features by worst-tail bad rate"
    )

    # Make labels look nice
    fig.update_traces(textposition="outside")

    fig.update_layout(
        yaxis=dict(categoryorder="total ascending"),
        xaxis_tickformat=".2f" if show_pct else ".3f",
        margin=dict(l=200, r=50, t=60, b=50),
        height=max(500, 35 * len(dfp))
    )

    fig.show()
